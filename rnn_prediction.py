# -*- coding: utf-8 -*-
"""RNN_prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CLwfg9KjxDXfSDyGSoPDgyxjXiBnmRaA

上傳檔案至Colab
---
"""

from google.colab import files
uploaded = files.upload()

"""讀取CSV
---
繪圖
"""

import io
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
csv_path = io.BytesIO(uploaded['international-airline-passengers.csv'])  # Colab 檔案位置
dataset = pd.read_csv(csv_path, usecols=[1])   # pandas 讀取csv
dataset = dataset.values
dataset = dataset.astype('float32')

### 繪圖
plt.plot(dataset)
plt.xlabel("Time(momth)")
plt.ylabel("Passengers")
plt.title("international airline passengers")
plt.show()

"""正規化(0~1)"""

### min_max normalize
#min_d = min(dataset)
#max_d = max(dataset)
#def normalize_numeric_data(data, min_d, max_d):   
#    return (data-min_d)/(max_d - min_d)
#dataset_scaled = normalize_numeric_data(dataset, min_d, max_d)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
dataset_scaled = scaler.fit_transform(dataset)

### 繪圖(normalize)
plt.plot(dataset_scaled)
plt.xlabel("Time(momth)")
plt.ylabel("Passengers")
plt.title("international airline passengers with normalize")
plt.show()

"""將資料區分成2/3、1/3，分別為train、test
---
"""

train_size = int(len(dataset_scaled) * (2/3))  # dataset長度的2/3為訓練資料的長度
test_size = len(dataset_scaled) - train_size   # 其餘為測試資料長度
train, test = dataset_scaled[0:train_size,:], dataset_scaled[train_size:,:] # dataset第1筆~第96筆為訓練用資料，97~144測試用資料

"""建立預測模型所需的訓練資料(X為輸入資料，Y為預測ground turth)
---
"""

def create_dataset(data, back_time): 
	dataX, dataY = [], []
	for i in range(len(data)-back_time):  
		dataX.append(data[i:(i+back_time), 0])
		dataY.append(data[i + back_time, 0])
	return np.array(dataX), np.array(dataY)
back_time = 1
trainX, trainY = create_dataset(train, back_time)
testX, testY = create_dataset(test, back_time)
# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], back_time, 1))
testX = np.reshape(testX, (testX.shape[0], back_time, 1))

"""建立模型(RNN)
---
"""

#from tensorflow import keras
#from tensorflow.keras.layers import Input, LSTM, Dropout, Dense
#from tensorflow.keras.models import Sequential
#import tensorflow as tf
import keras
from keras.layers import SimpleRNN, Dense 
input = keras.Input(shape=(back_time,1))
x = SimpleRNN(32, return_sequences=True)(input)
x = SimpleRNN(16, return_sequences=True)(x)
x = SimpleRNN(4)(x)
output = Dense(1)(x)
model = keras.Model(input, output)
model.summary()

"""訓練模型
---
"""

opt = keras.optimizers.Adam(lr=1e-3)
model.compile(loss='mean_squared_error', optimizer=opt)
model.fit(trainX, trainY, epochs=100, verbose=2)

"""預測模型
---
"""

testPredict = model.predict(testX)

"""輸出視覺化
---
"""

### 回復預測值為原始數據的規模(利用訓練資料的minimum和maximum)
#def inverse_normalized(data, min_d, max_d):
#    return data*(max_d - min_d)+min_d
#testPredict = inverse_normalized(testPredict, min_d, max_d)
testPredict = scaler.inverse_transform(testPredict)
testPredict = testPredict.reshape((len(testPredict),1))

### 繪圖
testPredictPlot = np.empty(dataset.shape)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainX)+back_time*2:len(dataset), :] = testPredict # shift, 將testPredict放入對應位置
x = range(len(dataset))
plt.plot(x, dataset, label='origin data', color='b')
plt.plot(x, testPredictPlot, label='testPtrdict', color='g')
plt.legend()
plt.show()